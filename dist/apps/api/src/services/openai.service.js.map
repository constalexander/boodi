{
  "version": 3,
  "sources": ["../../../../../apps/api/src/services/openai.service.ts"],
  "sourcesContent": ["import OpenAI from \"openai\";\nimport { Stream } from \"openai/streaming.mjs\";\nimport { ChatCompletionChunk } from \"openai/resources/index.mjs\";\nimport {\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n} from \"openai/resources/index.mjs\";\nimport config from \"../configs/app.config.js\";\n\nexport const ai = new OpenAI({\n  apiKey: config.openai.key,\n});\n\nexport const getStreamingCompletion = async (\n  extraParams: any\n): Promise<Stream<ChatCompletionChunk>> => {\n  const params: ChatCompletionCreateParamsStreaming = {\n    ...defaultParamsStreaming,\n    ...extraParams,\n    messages: [...defaultParamsStreaming.messages, ...extraParams.messages],\n  };\n\n  const completion = await ai.chat.completions.create(params);\n  return completion;\n};\n\nexport const defaultParamsNonStreaming: ChatCompletionCreateParamsNonStreaming =\n  {\n    model: config.openai.model,\n    temperature: 0.5,\n    max_tokens: 1024,\n    messages: [\n      {\n        role: \"system\",\n        content: config.prompts.initBoodi,\n      },\n    ],\n  };\n\nexport const defaultParamsStreaming: ChatCompletionCreateParamsStreaming = {\n  ...defaultParamsNonStreaming,\n  stream: true,\n};\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAAmB;AAOnB,wBAAmB;AAEZ,MAAM,KAAK,IAAI,cAAAA,QAAO;AAAA,EAC3B,QAAQ,kBAAAC,QAAO,OAAO;AACxB,CAAC;AAEM,MAAM,yBAAyB,OACpC,gBACyC;AACzC,QAAM,SAA8C;AAAA,IAClD,GAAG;AAAA,IACH,GAAG;AAAA,IACH,UAAU,CAAC,GAAG,uBAAuB,UAAU,GAAG,YAAY,QAAQ;AAAA,EACxE;AAEA,QAAM,aAAa,MAAM,GAAG,KAAK,YAAY,OAAO,MAAM;AAC1D,SAAO;AACT;AAEO,MAAM,4BACX;AAAA,EACE,OAAO,kBAAAA,QAAO,OAAO;AAAA,EACrB,aAAa;AAAA,EACb,YAAY;AAAA,EACZ,UAAU;AAAA,IACR;AAAA,MACE,MAAM;AAAA,MACN,SAAS,kBAAAA,QAAO,QAAQ;AAAA,IAC1B;AAAA,EACF;AACF;AAEK,MAAM,yBAA8D;AAAA,EACzE,GAAG;AAAA,EACH,QAAQ;AACV;",
  "names": ["OpenAI", "config"]
}
