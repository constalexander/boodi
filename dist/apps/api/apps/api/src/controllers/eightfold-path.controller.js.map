{
  "version": 3,
  "sources": ["../../../../../../../apps/api/src/controllers/eightfold-path.controller.ts"],
  "sourcesContent": ["import { NextFunction, Request, Response } from \"express\";\r\nimport {\r\n  ChatCompletionChunk,\r\n  ChatCompletionCreateParamsNonStreaming,\r\n  ChatCompletionCreateParamsStreaming,\r\n} from \"openai/resources/index.mjs\";\r\nimport config from \"../configs/app.config.js\";\r\nimport {\r\n  ai,\r\n  defaultParamsStreaming,\r\n  getStreamingCompletion,\r\n} from \"../services/openai.service.js\";\r\nimport { saveInteraction } from \"../services/supabase.service.js\";\r\nimport { Stream } from \"openai/streaming.mjs\";\r\n\r\n// export const askFirstOnly = async (\r\n//   req: Request,\r\n//   res: Response,\r\n//   next: NextFunction\r\n// ) => {\r\n//   const params: ChatCompletionCreateParamsNonStreaming = {\r\n//     messages: [\r\n//       {\r\n//         role: \"system\",\r\n//         content: `${config.prompts.boodi}${config.prompts.eightfoldPathFirstOnly}`,\r\n//       },\r\n//       {\r\n//         role: \"user\",\r\n//         content: `${req.body.suffering}`,\r\n//       },\r\n//     ],\r\n//     model: config.openai.model,\r\n//     temperature: 0.25,\r\n//     max_tokens: 128,\r\n//     n: 1,\r\n//     stop: null,\r\n//   };\r\n//   const completion = await ai.chat.completions.create(params);\r\n\r\n//   res.json({\r\n//     result: completion.choices[0].message.content ?? \"Please try again\",\r\n//   });\r\n// };\r\n\r\n// export const askFull = async (\r\n//   req: Request,\r\n//   res: Response,\r\n//   next: NextFunction\r\n// ) => {\r\n//   const params: ChatCompletionCreateParamsNonStreaming = {\r\n//     messages: [\r\n//       {\r\n//         role: \"system\",\r\n//         content: `${config.prompts.boodi}${config.prompts.eightfoldPathFull}`,\r\n//       },\r\n//       {\r\n//         role: \"user\",\r\n//         content: `${req.body.suffering}`,\r\n//       },\r\n//     ],\r\n//     model: config.openai.model,\r\n//     temperature: 0.25,\r\n//     max_tokens: 1024,\r\n//     n: 1,\r\n//     stop: null,\r\n//   };\r\n\r\n//   const completion = await ai.chat.completions.create(params);\r\n\r\n//   res.json({\r\n//     result: completion.choices[0].message.content ?? \"Please try again\",\r\n//   });\r\n// };\r\n\r\n// export const askFullStreaming = async (\r\n//   req: Request,\r\n//   res: Response,\r\n//   next: NextFunction\r\n// ) => {\r\n//   res.setHeader(\"Content-Type\", \"text/event-stream\");\r\n//   res.setHeader(\"Cache-Control\", \"no-cache\");\r\n//   res.setHeader(\"Connection\", \"keep-alive\");\r\n\r\n//   const params: ChatCompletionCreateParamsStreaming = {\r\n//     ...defaultParamsStreaming,\r\n//   };\r\n\r\n//   const stream = await getStreamingCompletion(params);\r\n\r\n//   for await (const chunk of stream) {\r\n//     const text = chunk.choices[0]?.delta.content || \"\";\r\n//     res.write(text);\r\n//   }\r\n\r\n//   res.end();\r\n// };\r\n\r\nexport const askFull = async (\r\n  req: Request,\r\n  res: Response,\r\n  next: NextFunction\r\n) => {\r\n  if (!req.ws) return;\r\n  const ws = await req.ws();\r\n\r\n  ws.on(\"error\", console.error);\r\n\r\n  ws.on(\"message\", (msg: string) => {\r\n    const msgObj = JSON.parse(msg);\r\n\r\n    const startStream = async (message: string) => {\r\n      const params = {\r\n        messages: [\r\n          {\r\n            role: \"system\",\r\n            content: config.prompts.eightfoldPathFull,\r\n          },\r\n          {\r\n            role: \"user\",\r\n            content: message,\r\n          },\r\n        ],\r\n        max_tokens: 512,\r\n      };\r\n\r\n      const stream: Stream<ChatCompletionChunk> = await getStreamingCompletion(\r\n        params\r\n      );\r\n\r\n      let output = \"\";\r\n      for await (const chunk of stream) {\r\n        const token = chunk.choices[0]?.delta.content || \"\";\r\n        output += token;\r\n\r\n        ws.send(token);\r\n      }\r\n\r\n      ws.close();\r\n\r\n      await saveInteraction(\r\n        \"/eightfold-path/full\",\r\n        message,\r\n        output,\r\n        msgObj.userUUID\r\n      );\r\n    };\r\n\r\n    startStream(msgObj.suffering);\r\n  });\r\n};\r\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA,wBAAmB;AACnB,4BAIO;AACP,8BAAgC;AAqFzB,MAAM,UAAU,OACrB,KACA,KACA,SACG;AACH,MAAI,CAAC,IAAI;AAAI;AACb,QAAM,KAAK,MAAM,IAAI,GAAG;AAExB,KAAG,GAAG,SAAS,QAAQ,KAAK;AAE5B,KAAG,GAAG,WAAW,CAAC,QAAgB;AAChC,UAAM,SAAS,KAAK,MAAM,GAAG;AAE7B,UAAM,cAAc,OAAO,YAAoB;AAC7C,YAAM,SAAS;AAAA,QACb,UAAU;AAAA,UACR;AAAA,YACE,MAAM;AAAA,YACN,SAAS,kBAAAA,QAAO,QAAQ;AAAA,UAC1B;AAAA,UACA;AAAA,YACE,MAAM;AAAA,YACN,SAAS;AAAA,UACX;AAAA,QACF;AAAA,QACA,YAAY;AAAA,MACd;AAEA,YAAM,SAAsC,UAAM;AAAA,QAChD;AAAA,MACF;AAEA,UAAI,SAAS;AACb,uBAAiB,SAAS,QAAQ;AAChC,cAAM,QAAQ,MAAM,QAAQ,CAAC,GAAG,MAAM,WAAW;AACjD,kBAAU;AAEV,WAAG,KAAK,KAAK;AAAA,MACf;AAEA,SAAG,MAAM;AAET,gBAAM;AAAA,QACJ;AAAA,QACA;AAAA,QACA;AAAA,QACA,OAAO;AAAA,MACT;AAAA,IACF;AAEA,gBAAY,OAAO,SAAS;AAAA,EAC9B,CAAC;AACH;",
  "names": ["config"]
}
